# dbt_project.yml
# ---------------
# This is the main configuration file for LedgerLine.
# Here we define the project name, version, where the models live,
# how they should be materialized, and other global behaviors.

name: 'ledgerline'
version: '1.0.0'
config-version: 2

profile: 'ledgerline'  # dbt Cloud ignores this for jobs/IDE

model-paths:    ['models']
analysis-paths: ['analyses']
test-paths:     ['tests']
seed-paths:     ['seeds']
macro-paths:    ['macros']
snapshot-paths: ['snapshots']

target-path: 'target'  # dbt's scratch pad. This is where dbt puts compiled SQL and artifacts during a run.
clean-targets:   # List of directories dbt wipes when you run dbt clean.
  - 'target'
  - 'dbt_packages'

quoting:   # Quotation is not forced, allowing Snowflake to handle names case-insensitively.
  database:   false
  schema:     false
  identifier: false


models:
  ledgerline:
    +persist_docs: {relation: true, columns: true}  # Keeps column and model descriptions visible in dbt docs.

    staging:
      +schema: staging
      # We use ephemeral in staging so models compile as CTEs only,
      # feeding the history layer with lightly adapted data.
      # This keeps cost and clutter down.
      +materialized: ephemeral


    history:
      +schema: history

      # History strategy:
      # We track the full change history with custom macros.
      # Custom macros insert only new or changed rows.
      #
      # Each run:
      #  - Current OPEN rows are loaded from staging.
      #  - Prior OPEN rows missing in today's feed are converted to synthetic CLOSE rows.
      +materialized: incremental

      # Default for history is append (since our dimensions are append-only)
      # We override this with merge for the usage fact, since we are applying OPEN/CLOSE SCD-2 logic.
      +incremental_strategy: append

      # If the source has a new column, don't add it. Why:
      #   - We donâ€™t want source schema drift to silently alter history.
      #   - History is a contract. Any real schema change is modeled so marts remain stable.
      +on_schema_change: ignore


    refined:
      +schema: refined
      +materialized: table


    marts:
      +materialized: table
      usage:
        +schema: marts_usage
        # Contracts enforce that models have the declared columns, types, and nullability.
        # Quality gate that forces intentional, reviewed schema evolution.
        +contract: {enforced: true}



# Seeds are static CSVs versiond in Git. Best for small lookups (codes, catalogs, countries, currencies).
# For LedgerLine, price_book_daily and meter_usage_daily are seeded intentionally.
# In a real system, these would be ingested as sources.
seeds:
  +schema: seeds

  ledgerline:
    +quote_columns: false

    # Each seed defines its schema explicitly and a post-hook fills in 
    # load_ts if missing, so every row has a timestamp for lineage.

    atlas_crm_customer_info:
      +column_types:
        customer_code:  varchar
        customer_name:  varchar
        country_code:   varchar
        load_ts:        timestamp_ntz
      +post-hook:
        - "update {{ this }} set load_ts = to_timestamp_ntz('{{ run_started_at }}') where load_ts is null"

    atlas_catalog_product_info:
      +column_types:
        product_code:   varchar
        product_name:   varchar
        category:       varchar
        load_ts:        timestamp_ntz
      +post-hook:
        - "update {{ this }} set load_ts = to_timestamp_ntz('{{ run_started_at }}') where load_ts is null"

    atlas_catalog_plan_info:
      +column_types:
        plan_code:      varchar
        plan_name:      varchar
        product_code:   varchar
        billing_period: varchar
        load_ts:        timestamp_ntz
      +post-hook:
        - "update {{ this }} set load_ts = to_timestamp_ntz('{{ run_started_at }}') where load_ts is null"

    atlas_currency_info:
      +column_types:
        currency_code:  varchar
        currency_name:  varchar
        decimal_digits: number
        load_ts:        timestamp_ntz
      +post-hook:
        - "update {{ this }} set load_ts = to_timestamp_ntz('{{ run_started_at }}') where load_ts is null"

    atlas_country_info:
      +column_types:
        country_code:   varchar
        country_name:   varchar
        load_ts:        timestamp_ntz
      +post-hook:
        - "update {{ this }} set load_ts = to_timestamp_ntz('{{ run_started_at }}') where load_ts is null"

    atlas_price_book_daily:
      +column_types:
        product_code:   varchar
        plan_code:      varchar
        price_date:     date
        unit_price:     number(18,6)
        load_ts:        timestamp_ntz
      +post-hook:
        - "update {{ this }} set load_ts = to_timestamp_ntz('{{ run_started_at }}') where load_ts is null"

    atlas_meter_usage_daily:
      +column_types:
        customer_code:  varchar
        product_code:   varchar
        plan_code:      varchar
        report_date:    date
        units_used:     number
        included_units: number
        load_ts:        timestamp_ntz
      +post-hook:
        - "update {{ this }} set load_ts = to_timestamp_ntz('{{ run_started_at }}') where load_ts is null"
